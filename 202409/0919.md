# TIL (Today I Learned)

# 9월 19일 목요일

# 😃 What I Learned

## ✨오늘 진행한 내용

- [x]  어드민 리뷰 상단 노출
    - [x]  사전학습 완료 및 검색 엔진 코드 분석
    - [x]  어드민에서 필드를 추가하면 opensearch에도 이에 대한 update 쿼리를 날려줘야 하는 듯???
        - [x]  맞음.. Best 리뷰 참고하면 됨
        - [x]  `ProductReviewSearchBulkUpdateEvent` 기반으로 찾아볼 것
        - [x]  상단노출 리뷰..는 캐시할 필요는 없음
        - [x]  `bulkUpsertByIds` 메서드 자체가 현재 masterMapper에 저장된 update된 review 정보를 다시 가져와서 이를 upsert해주는 것임
        - [x]  따라서 메서드를 새로 만들 필요는 없고 이벤트만 처리해주면 해결될듯! (생각보다 오래 안걸릴 것 같음)
        - [x]  근데 기술 및 용어, 배경을 이해하는게 더 중요할 것 같음
    - [x]  기반하여 필요시 로직 수정
    - [x]  AWS Opensearch
        - [x]  템플릿에 새로운 필드 추가
        - [x]  템플릿에만 추가되면 이미 만들어진 인덱스에 적용 안됨 → 수동으로 업데이트 by 동적 매핑
    - [x]  AWS OpenSearch 관련 문서 작성중
- [x]  Aws batch ECS 클러스터 자동 생성 원리 테스트
    - [x]  맞음. 컴퓨팅 환경 만들 때 AWS에서 자동으로 만들어주는 ECS 클러스터

## 공부한 내용

### 인프런 아키텍처 2022, 2023, 2024

- 5개의 목적 조직으로 변경 후 거대한 레거시 프로젝트 복제 후 자기 조직에 필요한 코드 외에 모두 삭제하여 분리
    - 이 과정에서 인프라도 5배로 늘려야 함으로 IaC(Infrastructure as Code), 즉 코드로 인프라 관리
    - 테라폼 등이 있으나 인프런은 pulumi 사용
- 한 개의 데이터베이스 바라보는 과정에서 어떤 쿼리 때문에 문제가 발생했는지 원인 찾기 어려움
    - 조직 별로 MySQL 계정을 분리하여 쿼리 부모 조직을 트랙킹할 수 있도록 함
- AVIF ⇒ 60% 이미지 트래픽 개선
- **카테고리 정보 트래픽 매일 150G 발생**
    - ElasticCache 등의 캐시 적용하여 RDS 부하 줄였으나 캐시로 가는 트래픽이 RDS로 직접 가는 트래픽과 크게 차이가 없었음
    - 애플리케이션의 로컬 캐시로 변경 (Java 에서 EHCache 등)
    - 이 과정에서 결국 로드밸랜서 → EC2 트래픽은 동일함
    - API 데이터는 JSON Format임으로 결국 JSON 파일이나 다름이 없다
    - 그리고 많아야 하루에 한번, 길면은 한달에 한 번밖에 변경 안한다.
    - 그냥 CDN 캐시 하면 안될까??
    - 그러면 Json을 어디에 저장?
        - S3
            - 카테고리 업데이트마다 S3 파일 교체 필요, File Write 필요
        - API 응답 캐시
            - 지금 아키텍처 그대로 사용하면서 요청 감소시킬 수 있는 방법으로 사용함
    - 근데 못씀 (헤더도 캐싱됨)
        - cache-control에 따라 헤더에 사용자 세션 쿠키도 같이 캐싱될 수 있음
        - default로 하면 안됨
        - 대부분의 로그인 관련 이슈가 CDN 캐시 문제였다고 한다.
- 리버스 프록시
    - 같은 path에서의 express(legacy), Next.js(new) 서버를 분기하고자 함
    - AS-IS
        - cloudfront : 분기 갯수 제한, 복잡한 쿠키 설정 등의 세부적인 설정 불가
    - TO-BE
        - traefik
            - go 기반 고차원 조건 가능하고 숫자 제약 없는 Route 구성
            - git 버전 관리 → revert 관리로 원복 쉽게 함

### 29cm 마이크로서비스 아키텍처 전환

- 스트랭글러 패턴
    - 새로운 프로젝트에 동일한 기능의 API를 만들고 앞단에 로드밸런서를 두어 트래픽을 점진적으로 이동시키는 방식
- 의존도가 낮은 도메인부터 전환 vs 비즈니스 임팩트가 큰 도메인부터 전환
- 표준 구현 가이드
    - 특정 기술에 종속되지 않으면서 요구사항을 잘 표현하는 도메인
    - 도메인의 실행을 ㅜ이해 필요한 세부 기술
    - 둘 간의 연결을 위한 추상화된 인터페이스와 이에 대한 의존성 주입 ⇒ 의존성 역전 DIP
- 동료 개발자 채용
    - 현실적인 대안으로 위한 기술 스택 전환 (자바 스프링)
- 처음 도메인을 쪼갤 때에는?
    - 우선 크게 쪼개고 이후에 세분화하자

- 장애 회고
    
    검색 엔진 부하 문제 (검색에 더불어 추천 또한 사용하고 있었음 (제품 상세 데이터를 여기서 가져오고있었음)
    
    장기적인 해결책
    
    - Materialized View for Micro Service
        - 클라이언트에서 다양한 도메인의 정보를 필요로 할 때
            - 마이크로서비스는 도메인별로 API를 호출하고 응답값을 조합해야하는 문제
        - 구축 방안
            - 클라이언트가 필요로 하는 정보를 정의한 후
            - 각각의 도메인 서비스에서 필요한 정보를 사전에 수신하여 별도로 저장
            - 배치나 트랜잭션 이벤트 발생시 카프카에서 이벤트를 받아서 view 쪽에서 컨슈머가 이벤트를 통해 반정규화된 데이터를 갱신할 수 있다. 실시간성이 중요한 요즘 후자가 더 좋다고 판단
            - JSON 형태의 데이터 + 라이트 성능? ⇒ MongoDB로 구축
    
    단기적인 해결책
    
    - 응답 간소화
        - 인덱스에서 필드 100개를 다가져옴 (20개만 가져올 수 있지 않는가?)
        - 불필요한 CPU, memory
    - fallback 구현
        - 유저에게 중간 상태의 응답이라도 주자
        - 추천서배스 장애 발생시 default 응답을 제공할 수 있도록 ⇒ 추천 응답이 fail 되기 보다는 로컬 캐시에 저장된 과거 시점의 성공 응답을 대신 내려주는 방향으로 구현
    - ES 노드 증설
- 서비스 디자인 일관성 ⇒ 개발 디자인 문서

### 29cm 카테고리 자동완성 개발

- [https://medium.com/29cm/카테고리-자동완성-개발기-93069d5835c4](https://medium.com/29cm/%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC-%EC%9E%90%EB%8F%99%EC%99%84%EC%84%B1-%EA%B0%9C%EB%B0%9C%EA%B8%B0-93069d5835c4)

### 인프콘 : 하루 1억 건 이상을 처리하는 견고한 포인트 시스템 구축하기

- AS-IS
    - 포인트별 테이블 생성
    - 포인트 잔액 테이블 사용
    - 새로운 포인트 타입 추가 불편
    - 적립 내역 조회 성능 저하 → 포인트 타입만큼 테이블 갯수 join
- TO-BE
    - 포인트 공통 테이블
    - 타입, 서브타입 필드 추가
    - 그러나
        - 타입 안정성을 잃음
        - 포인트 타입에 따른 테이블 최적화 불가

- 문제점 1 : 데이터 정합성 문제
    - 포인트 히스토리 쿼리 & 포인트 밸런스 업데이트 쿼리 중 1개만 처리되는 문제
    - 트랜잭션으로 처리
- 문제점 2 : 음수 잔액
    - Time-of-check to time-to-use
    - 여러 스레드에서 API가 실행될 때 잔액 확인 시점에 따라 실행되면 안되는 로직이 실행되는 문제가 발생 가능
    - 실제 발생 예시
        - 네트워크 지연
        - 버튼 연타
        - 재시도 계층
        - 어뷰저
    - 잠금을 이용하여 처리
- 문제점 3
    - 어플리케이션 로직 버그 > 긴급 대응 과정에서 수동 지급 처리 & 실수
    - 정합성이 어긋났을 때의 디버깅이 어려움
    - point_balance 를 history 기반으로 계속 update 하는 과정에서 정보 유실이 발생할 수 있음
    - 두 테이블을 합쳐서 history와 balance를 같이 존재하도록 설계
    - 디버깅이 편리하고 테이블만 보고 로직을 파악하는데 쉬움
    - 테이블을 줄이면서 트랜잭션이 불필요하다는 장점
    - 잔액은 레코드의 balance

- 개선 1
    - 잠금 점유 / 반환하는 과정을 없앨 수 없을까?
    - 비관적 잠금 → 낙관적 잠금 (versoning)
    - user_id & version 유니크 제약
    - 잔액/버전 을 동시에 확인하여 이미 존재하는 버전이 있다면 데이터베이스 레벨에서 삽입이 물가해짐
- 개선 2
    - 1년 이상 미사용 포인트 소멸
    - balance = deposit_sum + withdraw_sum 나누어서 관리
        - 얻은 포인트 + 소모한 포인트

- 성능 확장 1
    - 분석계 분리 : dynamoDB → Data lake (S3)
- 해결해야할 문제
    - 효율적인 과거 데이터 삭제의 어려움
    - MySQL : 파티셔닝으로 나누어 삭제
    - DynamoDB : TTL을 주어 삭제 가능
    - 그러나 위에서 설계한 테이블은 삭제하면 안되는 로직이다!

- 금융 시스템 구축을 위한 엔지니어링 원칙
    - Immutable and Durable > 실수했으면 지우지 말고 원복하는 레코드를 추가
    - Data record at the smallest grain >
    - Idempotency > 멱등성!

### 테스트 코드

- 단위 테스트
- 통합 테스트
    - 내부 의존성 : DB → 제어 가능, 테스트 DB 사용
    - 외부 의존성 : SMTP, HTTPClient → 제어 불가능, Mocking 객체 이용
- E2E 테스트

## ElasticSearch

### 루씬이란?

- 자바로 만들어진 고성능 정보 검색 “라이브러리”
- 과정
    - 검색 대상 텍스트 확보 (루씬 X)
    - 루씬 문서 (document) 생성
    - 문서 텍스트 분석
        - 루씬에는 텍스트 분석기들이 내장. 직접 구현하거나 여러 개의 내장 분석기를 연결해 구성 가능
    - 색인에 문서 추가
    - 색인 문서 추가

- 검색
    - 정확도 & 재현율
        - 정확도 : 관련 없는 문서를 얼마나 제외하는지
        - 재현율 : 얼마나 빼먹지 않는지
    - 검색 질의 파싱 : QueryParser가 검색어를 query 객체로 변환
    - 질의
        1. 순수 boolean : yes or no
        2. 벡터 공간 모델 : 벡터 거리 계산으로 유사도, 연관도 산출 가능
        3. 확률 모델 (루씬 X) : 개별 문서가 질의와 일치할 확률 계산
    - 결과 출력

### 템플릿으로 인덱스 만들기 vs 인덱스 직접 만들기

- /_index_template/{index_name} vs /{index_name}
    - `PUT /_index_template/{index_name}`
        - 특정 패턴에 따라 향후 생성될 인덱스에 자동으로 설정될 설과 매핑을 미리 정의함
        - 여러 인덱스를 동일한 설정으로 자동 생성해야하거나 인덱스가 정기적으로 생성되면서 동일한 매핑과 설정을 유지해야할 때 유용
    - `PUT /{index_name}`
        - 새로운 인덱스를 직접 생성
        - 템플릿이 적용되는 것이 아니라 이 요청 자체로 인덱스가 만들어지고 설정과 매핑이 정의됨
        - 특정 인덱스를 명시적으로 생성하고, 그 인덱스만 관리할 때 유용
    - 그렇다면, 템플릿에는 동적 매핑이 적용될까?
        - 안된다. 템플릿으로 생성된 인덱스에 동적 매핑으로 필드가 추가되면 그 개별 인덱스에만 필드가 추가되며 템플릿 자체에는 추가되지 않는다
    - 템플릿 조회 방법
        - `GET /_index_template/{template_name}`

- **템플릿 수정 방법**
    - **주의 : 템플릿으로 이미 만들어진 인덱스는 템플릿이 업데이트 되어도 매핑이 변경되지 않는다**
        - **따라서 인덱스는 수동으로 추가해주어야 한다**
- 참고
    - 템플릿은 인덱스를 만들 때의 이름이 index_patterns에 부합하는 경우에 자동으로 지정된다.
    
    ```json
    "index_template": {
            "index_patterns": [
              "reviews"
            ],
    ```
    
    - 따라서 인덱스를 만들 때 패턴에 부합하는 템플릿이 있다면 아무것도 세부 지정을 안하고 PUT으로 만들 수 있다.
    - PUT /{index_name} 으로 인덱스를 만들 때 세부내용을 넣는다면 해당되는 템플릿이 있다고 해도 무시된다.

## ✨내일 진행할 내용

- [ ]  할 수 있는게 없는데..
- [ ]  리뷰 마무리 (엣지 케이스나 테스트 할 만한 부분 생각해보기)
    - [ ]  QA, Staging, Production도 해야함 > 이건 코비님 확인 받고 진행
    - [ ]  API 문서 재검토
- [ ]  검색 엔진 추가 학습

# 😜 Today’s Small Happiness

# 🧐 Let’s Think About It

- 로컬 캐시가 정확히 뭐지?
    - 주로 **단일 애플리케이션 서버**에서 사용되는 **로컬 캐시**로, 같은 서버 내에서만 캐시를 제공한다.
    - **서버 간 데이터 공유는 불가능하다**
        - 확장성 한계
    - 네트워크 경로가 불필요하여 지연이 없다
    - Java에서는 ConcurrentHashmap, **Ehcache** 등이 있다.
        - Ehcache는 Disk 저장 (swapping)을 지원한다
        - 즉, 메모리 제한 없이 사용할 수 있다. 그렇지만 메모리에 많이 초과하게 사용한다면 스와핑으로 인해 성능이 저하된다
    - **언제 사용?**
        - **네트워크 지연을 피하고 싶을 때**
        - 서버간의 캐시 데이터 일관성이 중요하지 않을 때
        - 따라서 인프런에서 카테고리 정보를 내려줄 때 db나 엘라스틱 서치에서 바뀌지도 않는 값을 네트워크 통신을 통해서 보내줄 필요가 없어 ehCache를 사용한 것이다.
- Spring Cache
    - 동일한 추상화를 통해 Redis, Ehcache 같은 다양한 캐시 구현체를 사용할 수 있음
    - **구현체는 설정에 따라 쉽게 교체 가능**
    - @Cacheable, @CacheEvict 등

# 🙀 Got Stuck..

- opensearch 동적 인덱싱 주의하자..! 새로운 필드 넣을 때 타입 주의..!
- boolean은 is가 자동으로 빼질 수 있음으로 is 네이밍을 가져가고 싶으면 Boolean으로 작업